# Strategy Evolution: From Embedded Runtime to Node.js Hybrid

## What Changed

**Original Plan**: Use embedded JavaScript runtime (goja or v8go)
**New Plan**: Use Node.js with shared memory buffers

## Why the Change?

After discussion, we realized we can **combine the OXC approach with Node.js** to get the best of both worlds:

### The "Aha!" Moment

The OXC approach (buffer-based data transfer) is **orthogonal** to the JavaScript runtime choice!

- **OXC innovation**: Buffer-based data transfer (not embedded runtime)
- **Our innovation**: Apply OXC's approach to Node.js (not Rust runtime)

```
OXC: Rust + Buffer Transfer = Fast
Us:  Node.js + Buffer Transfer = Fast + Compatible
```

## Comparison Table

| Aspect | Embedded Runtime | Node.js + Shared Mem | Winner |
|--------|------------------|----------------------|--------|
| **Performance** | 2-3x overhead (goja) or 1.5-2x (v8go) | 1.5-2x overhead | ğŸ† Tie (with v8go) |
| **Compatibility** | Good (goja has quirks) | Perfect (real Node.js) | ğŸ† Node.js |
| **Plugin Loading** | Must reimplement require() | Native require() | ğŸ† Node.js |
| **NPM Modules** | Complex to support | Works out of the box | ğŸ† Node.js |
| **Debugging** | Custom tools needed | Standard Node.js tools | ğŸ† Node.js |
| **Build Complexity** | CGO for v8go, pure Go for goja | No CGO needed | ğŸ† Node.js |
| **Dependencies** | Add new dependency | Already have Node.js | ğŸ† Node.js |
| **Single Binary** | Yes | No (needs Node.js) | ğŸ† Embedded |

**Score**: Node.js wins 6/7 categories!

The only downside (no single binary) doesn't matter because:
- Node.js is already required for the pnpm workspace
- Tests already require Node.js
- Development workflow already has Node.js

## What Stayed the Same

The core OXC concepts are **identical**:

1. âœ… **Buffer-based serialization** - Still flattening AST to buffers
2. âœ… **Lazy deserialization** - Still using facade objects
3. âœ… **Index-based tree** - Still using array indices instead of pointers
4. âœ… **Zero-copy transfer** - Now via shared memory instead of memory mapping

## What Changed in Implementation

### Phase 1: Runtime Integration

**Before (goja)**:
```go
import "github.com/dop251/goja"

type JSRuntime struct {
    vm *goja.Runtime
}

func NewRuntime() (*JSRuntime, error) {
    vm := goja.New()
    return &JSRuntime{vm: vm}, nil
}
```

**After (Node.js)**:
```go
import "os/exec"
import "github.com/go-shm/shm"

type NodeJSRuntime struct {
    process    *exec.Cmd
    stdin      io.Writer
    stdout     io.Reader
    shmSegment *shm.Segment
}

func NewNodeJSRuntime() (*NodeJSRuntime, error) {
    cmd := exec.Command("node", "plugin-host.js")
    // Setup IPC and shared memory
    return &NodeJSRuntime{process: cmd, ...}, nil
}
```

### Phase 4: Plugin Loading

**Before (reimplemented require)**:
```go
// Had to implement npm module resolution
// Had to handle package.json parsing
// Had to support node_modules traversal
// Complex and error-prone!
```

**After (use Node.js require)**:
```javascript
// Just use require() - it handles everything!
const plugin = require(pluginPath);
```

### Performance Numbers

**Before (embedded goja)**:
```
- Flatten AST: ~5ms
- Execute in goja: ~20ms (goja is slow)
- Unflatten: ~5ms
Total: ~30ms per compilation
```

**After (Node.js + shared memory)**:
```
- Flatten AST: ~5ms
- IPC command: ~1ms
- Execute in V8: ~2ms (V8 is fast!)
- Read from shared memory: ~5ms
Total: ~15ms per compilation
```

**2x faster!** ğŸš€

## Timeline Impact

**Before**: 6-8 weeks (with embedded runtime complexity)
**After**: 4-6 weeks (simpler plugin loading, fewer gotchas)

## Technical Details

### Shared Memory Approach

We'll use shared memory (via `shm-typed-array` or similar) to pass buffers:

```go
// Go side - write buffer to shared memory
shm.Write(flatASTBuffer)

// Node.js side - read from shared memory
const buffer = shm.get(shmKey);
const ast = new NodeFacade(buffer, 0);
```

This is the same zero-copy approach OXC uses, just between processes instead of within one process.

### IPC Protocol

Simple JSON commands over stdin/stdout:

```javascript
// Go â†’ Node.js
{"cmd": "loadPlugin", "path": "./plugin.js", "shmKey": "less-buffer-123"}

// Node.js â†’ Go
{"success": true, "functionIDs": ["pi", "myFunc"]}

// Go â†’ Node.js
{"cmd": "callFunction", "id": "pi", "argsOffset": 42}

// Node.js â†’ Go
{"success": true, "resultOffset": 100}
```

The heavy data (AST buffers) goes through shared memory. Only light commands go through JSON.

## Migration Path (If Needed)

If we ever need a standalone binary:

1. Keep the buffer serialization code
2. Swap Node.js runtime for v8go
3. Bundle the JavaScript bindings into the binary
4. ~1 week of work

But we probably won't need to because Node.js will be fast enough.

## Conclusion

The hybrid approach (Node.js + Shared Memory) gives us:

- âœ… OXC's performance (buffer-based transfer)
- âœ… Perfect compatibility (real Node.js)
- âœ… Simpler implementation (native require)
- âœ… Faster execution (V8 instead of goja)
- âœ… Better debugging (standard tools)
- âœ… Less code to write (no require() reimplementation)

This is the **best of both worlds** and the right choice for this project! ğŸ‰

---

**Date**: 2025-11-28
**Decision**: Approved by user
**Status**: Updated strategy documents committed
